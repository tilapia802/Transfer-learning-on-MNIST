{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 3-1 Softmax only #################\n",
    "\n",
    "# Step1: Get tensor from our HW2 model, according to our HW2 naming\n",
    "# Import meta graph of out HW2 checkpoint\n",
    "restore_saver = tf.train.import_meta_graph(\"./Team60_HW2.ckpt.meta\") \n",
    "# Get tensor we need in HW3 training\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "dropout_rate2 = tf.get_default_graph().get_tensor_by_name(\"dropout_rate:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "softY = tf.get_default_graph().get_tensor_by_name(\"softmax:0\")\n",
    "logits = softY.op.inputs[0]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2: Get the softmax layer\n",
    "learning_rate = 0.01\n",
    "# output_layer_vars means the variables you want to train\n",
    "# In HW3-1, we only need to train on the softmax layer, so we only get scope \"logits\" (from HW2 softmax layer)\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name = 'Adam2')\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step3: Keep only the softmax trainable variables\n",
    "# Calculate accuracy\n",
    "predY = tf.nn.in_top_k(logits, y, 1) # boolean\n",
    "accuracy = tf.reduce_mean(tf.cast(predY, tf.float32), name=\"accuracy\") # boolean -> 0/1\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team60_HW2.ckpt\n",
      "0\tValidation loss: 1.651778\tBest loss: 1.651778\tAccuracy: 41.33%\n",
      "1\tValidation loss: 1.759042\tBest loss: 1.651778\tAccuracy: 41.33%\n",
      "2\tValidation loss: 1.172509\tBest loss: 1.172509\tAccuracy: 52.67%\n",
      "3\tValidation loss: 1.338535\tBest loss: 1.172509\tAccuracy: 41.33%\n",
      "4\tValidation loss: 1.391729\tBest loss: 1.172509\tAccuracy: 47.33%\n",
      "5\tValidation loss: 1.286124\tBest loss: 1.172509\tAccuracy: 51.33%\n",
      "6\tValidation loss: 1.227214\tBest loss: 1.172509\tAccuracy: 52.00%\n",
      "7\tValidation loss: 1.085998\tBest loss: 1.085998\tAccuracy: 59.33%\n",
      "8\tValidation loss: 1.189639\tBest loss: 1.085998\tAccuracy: 51.33%\n",
      "9\tValidation loss: 1.341168\tBest loss: 1.085998\tAccuracy: 44.00%\n",
      "10\tValidation loss: 1.202298\tBest loss: 1.085998\tAccuracy: 50.67%\n",
      "11\tValidation loss: 1.282820\tBest loss: 1.085998\tAccuracy: 44.00%\n",
      "12\tValidation loss: 1.158277\tBest loss: 1.085998\tAccuracy: 44.67%\n",
      "13\tValidation loss: 1.235707\tBest loss: 1.085998\tAccuracy: 54.00%\n",
      "14\tValidation loss: 1.631800\tBest loss: 1.085998\tAccuracy: 39.33%\n",
      "15\tValidation loss: 1.195400\tBest loss: 1.085998\tAccuracy: 55.33%\n",
      "16\tValidation loss: 1.504926\tBest loss: 1.085998\tAccuracy: 44.00%\n",
      "17\tValidation loss: 1.053319\tBest loss: 1.053319\tAccuracy: 56.67%\n",
      "18\tValidation loss: 1.247258\tBest loss: 1.053319\tAccuracy: 50.67%\n",
      "19\tValidation loss: 1.208578\tBest loss: 1.053319\tAccuracy: 49.33%\n",
      "20\tValidation loss: 1.257980\tBest loss: 1.053319\tAccuracy: 48.67%\n",
      "21\tValidation loss: 1.336624\tBest loss: 1.053319\tAccuracy: 50.67%\n",
      "22\tValidation loss: 1.577072\tBest loss: 1.053319\tAccuracy: 37.33%\n",
      "23\tValidation loss: 1.185856\tBest loss: 1.053319\tAccuracy: 51.33%\n",
      "24\tValidation loss: 1.197979\tBest loss: 1.053319\tAccuracy: 48.67%\n",
      "25\tValidation loss: 1.215208\tBest loss: 1.053319\tAccuracy: 53.33%\n",
      "26\tValidation loss: 1.203219\tBest loss: 1.053319\tAccuracy: 52.00%\n",
      "27\tValidation loss: 1.289634\tBest loss: 1.053319\tAccuracy: 51.33%\n",
      "28\tValidation loss: 1.364721\tBest loss: 1.053319\tAccuracy: 41.33%\n",
      "29\tValidation loss: 1.184505\tBest loss: 1.053319\tAccuracy: 52.67%\n",
      "30\tValidation loss: 1.108803\tBest loss: 1.053319\tAccuracy: 53.33%\n",
      "31\tValidation loss: 1.218114\tBest loss: 1.053319\tAccuracy: 51.33%\n",
      "32\tValidation loss: 1.594392\tBest loss: 1.053319\tAccuracy: 40.67%\n",
      "33\tValidation loss: 1.163305\tBest loss: 1.053319\tAccuracy: 54.00%\n",
      "34\tValidation loss: 1.302271\tBest loss: 1.053319\tAccuracy: 38.67%\n",
      "35\tValidation loss: 1.086641\tBest loss: 1.053319\tAccuracy: 57.33%\n",
      "36\tValidation loss: 1.194600\tBest loss: 1.053319\tAccuracy: 52.00%\n",
      "37\tValidation loss: 1.300041\tBest loss: 1.053319\tAccuracy: 51.33%\n",
      "Early stop!\n",
      "Total training time: 2.4s\n",
      "INFO:tensorflow:Restoring parameters from ./Team60_HW3_1.ckpt\n",
      "Testing accuracy: 51.06%\n"
     ]
    }
   ],
   "source": [
    "# Step4: Start training and print every epoch\n",
    "# Import time because we need to measure training time\n",
    "import time\n",
    "# Variables that we need in training\n",
    "num_epochs = 1000\n",
    "early_stop = 20\n",
    "batch_size = 20\n",
    "best_loss = np.infty\n",
    "step_without_progress = 0 \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    restore_saver.restore(sess, \"./Team60_HW2.ckpt\")\n",
    "    \n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    time_start = time.time()\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data\n",
    "        rnd_idx = list(range(len(X_train2)))\n",
    "        np.random.shuffle(rnd_idx)\n",
    "        # Get every batch\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, dropout_rate2: 0.5})\n",
    "        # Get validation accuracy\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2, dropout_rate2: 1.0})\n",
    "        # Check the progress of training, and see if it need to early stop\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./Team60_HW3_1.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            step_without_progress = 0\n",
    "        else:\n",
    "            step_without_progress += 1\n",
    "            if step_without_progress > early_stop:\n",
    "                print(\"Early stop!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_3_1 = time_end - time_start\n",
    "    \n",
    "    print(\"Total training time: {:.1f}s\".format(time_end - time_start))\n",
    "# Testing\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team60_HW3_1.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2, dropout_rate2: 1.0})\n",
    "    print(\"Testing accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "    acc_3_1 = acc_test * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team60_HW2.ckpt\n",
      "0\tValidation loss: 1.721285\tBest loss: 1.721285\tAccuracy: 44.67%\n",
      "1\tValidation loss: 1.730600\tBest loss: 1.721285\tAccuracy: 40.00%\n",
      "2\tValidation loss: 1.364526\tBest loss: 1.364526\tAccuracy: 50.00%\n",
      "3\tValidation loss: 1.352564\tBest loss: 1.352564\tAccuracy: 52.00%\n",
      "4\tValidation loss: 1.792190\tBest loss: 1.352564\tAccuracy: 32.67%\n",
      "5\tValidation loss: 1.584202\tBest loss: 1.352564\tAccuracy: 41.33%\n",
      "6\tValidation loss: 1.248564\tBest loss: 1.248564\tAccuracy: 51.33%\n",
      "7\tValidation loss: 1.393138\tBest loss: 1.248564\tAccuracy: 52.67%\n",
      "8\tValidation loss: 1.397118\tBest loss: 1.248564\tAccuracy: 38.67%\n",
      "9\tValidation loss: 1.743944\tBest loss: 1.248564\tAccuracy: 34.00%\n",
      "10\tValidation loss: 1.381750\tBest loss: 1.248564\tAccuracy: 50.00%\n",
      "11\tValidation loss: 1.652308\tBest loss: 1.248564\tAccuracy: 44.67%\n",
      "12\tValidation loss: 1.575054\tBest loss: 1.248564\tAccuracy: 39.33%\n",
      "13\tValidation loss: 1.488151\tBest loss: 1.248564\tAccuracy: 51.33%\n",
      "14\tValidation loss: 1.561355\tBest loss: 1.248564\tAccuracy: 46.67%\n",
      "15\tValidation loss: 1.619631\tBest loss: 1.248564\tAccuracy: 44.67%\n",
      "16\tValidation loss: 1.702342\tBest loss: 1.248564\tAccuracy: 43.33%\n",
      "17\tValidation loss: 1.481524\tBest loss: 1.248564\tAccuracy: 44.67%\n",
      "18\tValidation loss: 1.543648\tBest loss: 1.248564\tAccuracy: 46.67%\n",
      "19\tValidation loss: 1.461749\tBest loss: 1.248564\tAccuracy: 52.67%\n",
      "20\tValidation loss: 1.668515\tBest loss: 1.248564\tAccuracy: 44.00%\n",
      "21\tValidation loss: 1.642827\tBest loss: 1.248564\tAccuracy: 47.33%\n",
      "22\tValidation loss: 1.538143\tBest loss: 1.248564\tAccuracy: 51.33%\n",
      "23\tValidation loss: 1.971831\tBest loss: 1.248564\tAccuracy: 41.33%\n",
      "24\tValidation loss: 1.654929\tBest loss: 1.248564\tAccuracy: 44.00%\n",
      "25\tValidation loss: 1.554189\tBest loss: 1.248564\tAccuracy: 47.33%\n",
      "26\tValidation loss: 1.529993\tBest loss: 1.248564\tAccuracy: 54.67%\n",
      "Early stop!\n",
      "Total training time of 3-1: 2.4s\n",
      "Total training time of 3-2: 1.2s\n",
      "Compare the training time of 3-1 and 3-2, we know that cache 5th layer really helps improving training speed!\n",
      "INFO:tensorflow:Restoring parameters from ./Team60_HW3_2.ckpt\n",
      "Testing accuracy: 50.50%\n"
     ]
    }
   ],
   "source": [
    "################# 3-2 Cache 5th layer #################\n",
    "\n",
    "# Step3.5: Cache 5th layer output before training\n",
    "# Get output of our HW2 hidden layer 5 \n",
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden_layer5/Elu:0\")\n",
    "\n",
    "# Step4: Start training and print every epoch (feed cached data)\n",
    "num_epochs = 1000\n",
    "early_stop = 20\n",
    "batch_size = 20\n",
    "best_loss = np.infty\n",
    "step_without_progress = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    restore_saver.restore(sess, \"./Team60_HW2.ckpt\")\n",
    "    \n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    time_start = time.time()\n",
    "    # Get cached output of hidden layer 5 that we just got (both training data and validation data)\n",
    "    train_cached = hidden5_out.eval(feed_dict={X: X_train2, y: y_train2, dropout_rate2: 0.5})\n",
    "    valid_cached = hidden5_out.eval(feed_dict={X: X_valid2, y: y_valid2, dropout_rate2: 1.0})\n",
    "     \n",
    "    for epoch in range(num_epochs):\n",
    "        # shuffle the data\n",
    "        rnd_idx = list(range(len(X_train2)))\n",
    "        np.random.shuffle(rnd_idx)\n",
    "        # Get batch (Use the cached training and validation data that we just got)\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = train_cached[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: X_batch, y: y_batch, dropout_rate2: 0.5})\n",
    "            \n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: valid_cached, y: y_valid2, dropout_rate2: 1.0})\n",
    "        \n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./Team60_HW3_2.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            step_without_progress = 0\n",
    "        else:\n",
    "            step_without_progress += 1\n",
    "            if step_without_progress > early_stop:\n",
    "                print(\"Early stop!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    time_end = time.time()\n",
    "    print(\"Total training time of 3-1: {:.1f}s\".format(time_3_1))\n",
    "    print(\"Total training time of 3-2: {:.1f}s\".format(time_end - time_start))\n",
    "    print(\"Compare the training time of 3-1 and 3-2, we know that cache 5th layer really helps improving training speed!\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team60_HW3_2.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2, dropout_rate2: 1.0})\n",
    "    print(\"Testing accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team60_HW2.ckpt\n",
      "0\tValidation loss: 293.591766\tBest loss: 293.591766\tAccuracy: 54.00%\n",
      "1\tValidation loss: 308.124908\tBest loss: 293.591766\tAccuracy: 54.67%\n",
      "2\tValidation loss: 207.326416\tBest loss: 207.326416\tAccuracy: 62.00%\n",
      "3\tValidation loss: 199.797241\tBest loss: 199.797241\tAccuracy: 62.00%\n",
      "4\tValidation loss: 252.381683\tBest loss: 199.797241\tAccuracy: 58.00%\n",
      "5\tValidation loss: 226.818054\tBest loss: 199.797241\tAccuracy: 61.33%\n",
      "6\tValidation loss: 213.641235\tBest loss: 199.797241\tAccuracy: 57.33%\n",
      "7\tValidation loss: 192.438065\tBest loss: 192.438065\tAccuracy: 60.00%\n",
      "8\tValidation loss: 247.706940\tBest loss: 192.438065\tAccuracy: 58.00%\n",
      "9\tValidation loss: 165.158127\tBest loss: 165.158127\tAccuracy: 55.33%\n",
      "10\tValidation loss: 192.968582\tBest loss: 165.158127\tAccuracy: 60.67%\n",
      "11\tValidation loss: 185.270111\tBest loss: 165.158127\tAccuracy: 56.00%\n",
      "12\tValidation loss: 234.035950\tBest loss: 165.158127\tAccuracy: 54.00%\n",
      "13\tValidation loss: 244.649048\tBest loss: 165.158127\tAccuracy: 58.67%\n",
      "14\tValidation loss: 242.381714\tBest loss: 165.158127\tAccuracy: 62.67%\n",
      "15\tValidation loss: 197.067886\tBest loss: 165.158127\tAccuracy: 68.67%\n",
      "16\tValidation loss: 238.874451\tBest loss: 165.158127\tAccuracy: 48.00%\n",
      "17\tValidation loss: 158.037643\tBest loss: 158.037643\tAccuracy: 72.00%\n",
      "18\tValidation loss: 254.472382\tBest loss: 158.037643\tAccuracy: 59.33%\n",
      "19\tValidation loss: 154.567245\tBest loss: 154.567245\tAccuracy: 69.33%\n",
      "20\tValidation loss: 188.552170\tBest loss: 154.567245\tAccuracy: 60.67%\n",
      "21\tValidation loss: 225.743164\tBest loss: 154.567245\tAccuracy: 61.33%\n",
      "22\tValidation loss: 176.129150\tBest loss: 154.567245\tAccuracy: 62.67%\n",
      "23\tValidation loss: 244.032669\tBest loss: 154.567245\tAccuracy: 60.00%\n",
      "24\tValidation loss: 142.739822\tBest loss: 142.739822\tAccuracy: 69.33%\n",
      "25\tValidation loss: 229.896240\tBest loss: 142.739822\tAccuracy: 60.00%\n",
      "26\tValidation loss: 186.851624\tBest loss: 142.739822\tAccuracy: 63.33%\n",
      "27\tValidation loss: 237.066025\tBest loss: 142.739822\tAccuracy: 60.67%\n",
      "28\tValidation loss: 176.958954\tBest loss: 142.739822\tAccuracy: 52.00%\n",
      "29\tValidation loss: 197.033524\tBest loss: 142.739822\tAccuracy: 59.33%\n",
      "30\tValidation loss: 247.927399\tBest loss: 142.739822\tAccuracy: 58.67%\n",
      "31\tValidation loss: 166.136490\tBest loss: 142.739822\tAccuracy: 55.33%\n",
      "32\tValidation loss: 176.595581\tBest loss: 142.739822\tAccuracy: 56.00%\n",
      "33\tValidation loss: 173.684601\tBest loss: 142.739822\tAccuracy: 62.00%\n",
      "34\tValidation loss: 238.317169\tBest loss: 142.739822\tAccuracy: 56.00%\n",
      "35\tValidation loss: 177.378479\tBest loss: 142.739822\tAccuracy: 58.67%\n",
      "36\tValidation loss: 239.771515\tBest loss: 142.739822\tAccuracy: 58.00%\n",
      "37\tValidation loss: 266.016815\tBest loss: 142.739822\tAccuracy: 51.33%\n",
      "38\tValidation loss: 230.790848\tBest loss: 142.739822\tAccuracy: 54.67%\n",
      "39\tValidation loss: 171.862518\tBest loss: 142.739822\tAccuracy: 64.67%\n",
      "40\tValidation loss: 165.714478\tBest loss: 142.739822\tAccuracy: 64.00%\n",
      "41\tValidation loss: 184.484238\tBest loss: 142.739822\tAccuracy: 62.67%\n",
      "42\tValidation loss: 279.698273\tBest loss: 142.739822\tAccuracy: 53.33%\n",
      "43\tValidation loss: 294.383545\tBest loss: 142.739822\tAccuracy: 44.00%\n",
      "44\tValidation loss: 241.922195\tBest loss: 142.739822\tAccuracy: 56.00%\n",
      "Early stop!\n",
      "INFO:tensorflow:Restoring parameters from ./Team60_HW3_3.ckpt\n",
      "Testing accuracy: 60.01%\n",
      "Accuracy of 3-1: 51.06%\n",
      "Accuracy of 3-3: 60.01%\n",
      "Compare the results of 3-1 and 3-3, we know that adding a new softmax layer can improve accuracy!\n"
     ]
    }
   ],
   "source": [
    "################# 3-3 4 layers instead #################\n",
    "reset_graph()\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "# Restore HW2 checkpoints\n",
    "restore_saver = tf.train.import_meta_graph(\"./Team60_HW2.ckpt.meta\")\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "dropout_rate2 = tf.get_default_graph().get_tensor_by_name(\"dropout_rate:0\")\n",
    "\n",
    "# Get output of our HW2 hidden layer 4 \n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden_layer4/Elu:0\")\n",
    "\n",
    "# Build new dense and softmax layer\n",
    "logits = tf.layers.dense(hidden4_out, num_classes, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "# Compute loss and accuracy\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "#loss = xentropy[20]\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# frozen the parameters in 4 layers only train the \"new_logits\" layer \n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "# Due to the same name \"Adam\" in Team60_HW2.ckpt.meta, we need to rename the optimizer.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "# Set the trainable parameters into minimize function\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()\n",
    "\n",
    "num_epochs = 1000\n",
    "early_stop = 20\n",
    "batch_size = 20\n",
    "best_loss = np.infty\n",
    "step_without_progress = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    restore_saver.restore(sess, \"./Team60_HW2.ckpt\")\n",
    "    \n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    # Retrain the model   \n",
    "    for epoch in range(num_epochs):\n",
    "        # shuffle the data\n",
    "        rnd_idx = list(range(len(X_train2)))\n",
    "        np.random.shuffle(rnd_idx)\n",
    "        \n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, dropout_rate2: 0.5})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2, dropout_rate2: 1.0})\n",
    "        \n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./Team60_HW3_3.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            step_without_progress = 0\n",
    "        else:\n",
    "            step_without_progress += 1\n",
    "            if step_without_progress > early_stop:\n",
    "                print(\"Early stop!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team60_HW3_3.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2, dropout_rate2: 1.0})\n",
    "    print(\"Testing accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "    \n",
    "    \n",
    "    print(\"Accuracy of 3-1: {:.2f}%\".format(acc_3_1))\n",
    "    print(\"Accuracy of 3-3: {:.2f}%\".format(acc_test * 100))\n",
    "    print(\"Compare the results of 3-1 and 3-3, we know that adding a new softmax layer can improve accuracy!\")\n",
    "    \n",
    "    acc_3_3 = acc_test * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 3-4 Bonus #################\n",
    "# In 3-4, we frozen hidden_layer 3 and 4\n",
    "# Retrian on hidden_layer 1,2 and new softmax layer\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Set the variables that need to be retrained\n",
    "# The unfrozen parameters contain in \"hidden_layer1\", \"hidden_layer2\", and \"new_logits\" layers\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden_layer[12]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "# Set the unfrozen parameters into minimize function\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./Team60_HW3_3.ckpt\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        # shuffle the data\n",
    "        rnd_idx = list(range(len(X_train2)))\n",
    "        np.random.shuffle(rnd_idx)\n",
    "        \n",
    "        # training in epoches\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, dropout_rate2: 0.5})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2, dropout_rate2: 1.0})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./Team60_HW3_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stop!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./Team60_HW3_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2, dropout_rate2: 1.0})\n",
    "    print(\"Testing accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "    \n",
    "    print(\"Accuracy of 3-3: {:.2f}%\".format(acc_3_3))\n",
    "    print(\"Accuracy of 3-4: {:.2f}%\".format(acc_test * 100))\n",
    "    print(\"Compare the results of 3-3 and 3-4, we know that unfreeze hidden 1 and 2 layers can get better!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
